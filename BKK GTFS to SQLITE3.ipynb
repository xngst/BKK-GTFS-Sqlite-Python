{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BKK GTFS CSV fileok SQLite adatbázisba írása"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### file forrás: https://bkk.hu/apps/gtfs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sqlite3\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: pythonnal letölteni a zip file-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_DIR = Path(\"/home/xunguist/Ipython_Notebooks/BKK adatbázis/GTFS/SQLITE_DB\")\n",
    "ZIP_DIR = Path(\"/home/xunguist/Ipython_Notebooks/BKK adatbázis/GTFS\")\n",
    "GTFS_DIR = ZIP_DIR/\"extracted\"\n",
    "zip_file = ZIP_DIR/\"budapest_gtfs_12_04_2021.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZIP kibontása\n",
    "with zipfile.ZipFile(zip_file) as zf:\n",
    "    zf.extractall(GTFS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTFS CSV-k beolvasása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.4 s, sys: 1.96 s, total: 33.4 s\n",
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(GTFS_DIR/\"agency.txt\",'r') as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    agency_to_db = [(col[\"agency_id\"], \n",
    "              col[\"agency_name\"],\n",
    "              col[\"agency_url\"],\n",
    "              col[\"agency_timezone\"],\n",
    "              col[\"agency_lang\"],\n",
    "              col[\"agency_phone\"]\n",
    "                    ) for col in dr]\n",
    "    \n",
    "with open(GTFS_DIR/\"calendar_dates.txt\",'r') as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    calendar_dates_to_db = [(col[\"service_id\"], \n",
    "              col[\"date\"],\n",
    "              col[\"exception_type\"])\n",
    "            for col in dr]\n",
    "\n",
    "with open(GTFS_DIR/\"routes.txt\",'r') as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    routes_to_db = [(col[\"agency_id\"], \n",
    "              col[\"route_id\"],\n",
    "              col[\"route_short_name\"],\n",
    "              col[\"route_long_name\"],\n",
    "              col[\"route_type\"],      \n",
    "              col[\"route_desc\"],\n",
    "              col[\"route_color\"],\n",
    "              col[\"route_text_color\"])\n",
    "            for col in dr]\n",
    "    \n",
    "with open(GTFS_DIR/\"trips.txt\",'r') as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    trips_to_db = [(col[\"route_id\"], \n",
    "              col[\"trip_id\"],\n",
    "              col[\"service_id\"],\n",
    "              col[\"trip_headsign\"],\n",
    "              col[\"direction_id\"],      \n",
    "              col[\"block_id\"],\n",
    "              col[\"shape_id\"],\n",
    "              col[\"bikes_allowed\"],\n",
    "              col[\"wheelchair_accessible\"],\n",
    "              col[\"boarding_door\"])\n",
    "            for col in dr]\n",
    "    \n",
    "with open(GTFS_DIR/\"stop_times.txt\",'r') as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    stop_times_to_db = [(col[\"trip_id\"], \n",
    "              col[\"stop_id\"],\n",
    "              col[\"arrival_time\"],\n",
    "              col[\"departure_time\"],\n",
    "              col[\"stop_sequence\"],      \n",
    "              col[\"stop_headsign\"],\n",
    "              col[\"pickup_type\"],\n",
    "              col[\"drop_off_type\"],\n",
    "              col[\"shape_dist_traveled\"])\n",
    "            for col in dr]\n",
    "\n",
    "with open(GTFS_DIR/\"stops.txt\",'r') as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    stops_to_db = [(col[\"stop_id\"], \n",
    "              col[\"stop_name\"],\n",
    "              col[\"stop_lat\"],\n",
    "              col[\"stop_lon\"],\n",
    "              col[\"stop_code\"],      \n",
    "              col[\"location_type\"],\n",
    "              col[\"parent_station\"],\n",
    "              col[\"wheelchair_boarding\"],\n",
    "              col[\"stop_direction\"])\n",
    "            for col in dr]\n",
    "    \n",
    "with open(GTFS_DIR/\"shapes.txt\",'r') as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    shapes_to_db = [(col[\"shape_id\"], \n",
    "              col[\"shape_pt_sequence\"],\n",
    "              col[\"shape_pt_lat\"],\n",
    "              col[\"shape_pt_lon\"],\n",
    "              col[\"shape_dist_traveled\"])\n",
    "            for col in dr]\n",
    "    \n",
    "with open(GTFS_DIR/\"pathways.txt\",'r') as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    pathways_to_db = [(col[\"pathway_id\"], \n",
    "              col[\"pathway_mode\"],\n",
    "              col[\"is_bidirectional\"],\n",
    "              col[\"from_stop_id\"],\n",
    "              col[\"to_stop_id\"],\n",
    "              col[\"traversal_time\"])\n",
    "            for col in dr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite adatbázis készítése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "UNIQUE constraint failed: routes.route_id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: UNIQUE constraint failed: routes.route_id"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "db_name = \"bkk_gtfs_db.db\"\n",
    "\n",
    "con = sqlite3.connect(DB_DIR/db_name)\n",
    "cursorObj = con.cursor()\n",
    "\n",
    "try:\n",
    "    cursorObj.execute(\"CREATE TABLE IF NOT EXISTS agency (agency_id, agency_name, agency_url, agency_timezone,agency_lang, agency_phone);\")\n",
    "    cursorObj.execute(\"CREATE TABLE IF NOT EXISTS routes (agency_id, route_id PRIMARY KEY, route_short_name,route_long_name,route_type,route_desc,route_color,route_text_color);\")\n",
    "    cursorObj.execute(\"CREATE TABLE IF NOT EXISTS trips (route_id, trip_id PRIMARY KEY, service_id,trip_headsign,direction_id,block_id,shape_id,bikes_allowed,wheelchair_accessible,boarding_door);\")\n",
    "    cursorObj.execute(\"CREATE TABLE IF NOT EXISTS stop_times (trip_id,stop_id,arrival_time,departure_time,stop_sequence,stop_headsign,pickup_type,drop_off_type,shape_dist_traveled);\")\n",
    "    cursorObj.execute(\"CREATE TABLE IF NOT EXISTS stops (stop_id,stop_name,stop_lat,stop_lon,stop_code,location_type,parent_station,wheelchair_boarding,stop_direction);\")\n",
    "    cursorObj.execute(\"CREATE TABLE IF NOT EXISTS calendar_dates (service_id,date,exception_type);\")\n",
    "    cursorObj.execute(\"CREATE TABLE IF NOT EXISTS shapes (shape_id,shape_pt_sequence,shape_pt_lat,shape_pt_lon,shape_dist_traveled);\")\n",
    "    cursorObj.execute(\"CREATE TABLE IF NOT EXISTS pathways (pathway_id PRIMARY KEY,pathway_type,from_stop_id,to_stop_id,traversal_time,wheelchair_traversal_time );\")\n",
    "    \n",
    "except (sqlite3.OperationalError, IntegrityError) as err:\n",
    "    print (err)\n",
    "    print(\"rolling back table creation...\")\n",
    "    con.rollback()    \n",
    "\n",
    "try:\n",
    "    cursorObj.executemany(\"INSERT INTO agency (agency_id, agency_name, agency_url, agency_timezone,agency_lang,agency_phone) VALUES (?,?,?,?,?,?);\", agency_to_db)\n",
    "    cursorObj.executemany(\"INSERT INTO routes (agency_id, route_id, route_short_name,route_long_name,route_type,route_desc,route_color,route_text_color) VALUES (?,?,?,?,?,?,?,?);\", routes_to_db)\n",
    "    cursorObj.executemany(\"INSERT INTO trips (route_id, trip_id, service_id,trip_headsign,direction_id,block_id,shape_id,bikes_allowed,wheelchair_accessible,boarding_door) VALUES (?,?,?,?,?,?,?,?,?,?);\", trips_to_db)\n",
    "    cursorObj.executemany(\"INSERT INTO stop_times (trip_id,stop_id,arrival_time,departure_time,stop_sequence,stop_headsign,pickup_type,drop_off_type,shape_dist_traveled) VALUES (?,?,?,?,?,?,?,?,?);\", stop_times_to_db)\n",
    "    cursorObj.executemany(\"INSERT INTO shapes (shape_id,shape_pt_sequence,shape_pt_lat,shape_pt_lon,shape_dist_traveled) VALUES (?,?,?,?,?);\", shapes_to_db)\n",
    "    cursorObj.executemany(\"INSERT INTO pathways (pathway_id,pathway_type,from_stop_id,to_stop_id,traversal_time,wheelchair_traversal_time) VALUES (?,?,?,?,?,?);\", pathways_to_db)\n",
    "    cursorObj.executemany(\"INSERT INTO stops (stop_id,stop_name,stop_lat,stop_lon,stop_code,location_type,parent_station,wheelchair_boarding,stop_direction) VALUES (?,?,?,?,?,?,?,?,?);\", stops_to_db)\n",
    "    cursorObj.executemany(\"INSERT INTO calendar_dates (service_id,date,exception_type) VALUES (?,?,?);\", calendar_dates_to_db)\n",
    "\n",
    "except sqlite3.OperationalError as OE:\n",
    "    print (OE)\n",
    "    print(\"rolling back table insertion...\")\n",
    "    con.rollback()\n",
    "    \n",
    "try:\n",
    "    cursorObj.execute(\"CREATE INDEX trips_route_index ON trips(trip_id);\")\n",
    "    cursorObj.execute(\"CREATE INDEX triops_trip_index ON trips(trip_id);\")\n",
    "    cursorObj.execute(\"CREATE INDEX trips_direction_index ON trips(direction_id);\")\n",
    "    cursorObj.execute(\"CREATE INDEX trips_block_index ON trips(block_id);\")\n",
    "    cursorObj.execute(\"CREATE INDEX stop_times_trip_index ON stop_times(trip_id);\")\n",
    "    cursorObj.execute(\"CREATE INDEX stop_times_stop_index ON stop_times(stop_id);\")\n",
    "except sqlite3.OperationalError as OE:\n",
    "    print (OE)\n",
    "    print(\"rolling back indexing...\")\n",
    "    con.rollback()  \n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file statisztika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file : 42.24 MB\n",
      "###########################\n",
      "stops.txt : 0.33 MB\n",
      "pathways.txt : 0.01 MB\n",
      "agency.txt : 0.0 MB\n",
      "calendar_dates.txt : 0.34 MB\n",
      "routes.txt : 0.03 MB\n",
      "trips.txt : 18.94 MB\n",
      "stop_times.txt : 280.12 MB\n",
      "feed_info.txt : 0.0 MB\n",
      "shapes.txt : 13.62 MB\n",
      "*összes unzippelt: 313.39 MB\n",
      "###########################\n",
      "bkk_gtfs_db.db : 517.14 MB\n"
     ]
    }
   ],
   "source": [
    "st_size = round(os.stat(zip_file)[6]/1000000,2)\n",
    "print(f\"ZIP file : {st_size} MB\")\n",
    "print(\"#\"*27)\n",
    "tot = 0\n",
    "for file in os.listdir(GTFS_DIR):\n",
    "    print(file, end=\" \")\n",
    "    part_size = os.stat(GTFS_DIR/file)[6]/1000000\n",
    "    print(f\": {round(part_size,2)} MB\")\n",
    "    tot += round(part_size, 2)\n",
    "print(f\"*összes unzippelt: {tot} MB\")\n",
    "print(\"#\"*27)\n",
    "st_size = round(os.stat(DB_DIR/db_name)[6]/1000000,2)\n",
    "print(f\"{db_name} : {st_size} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
